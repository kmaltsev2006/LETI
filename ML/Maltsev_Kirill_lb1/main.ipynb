{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":34377,"databundleVersionId":3220602,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Выставлю seed для тестирования используемых моделей:","metadata":{}},{"cell_type":"code","source":"SEED = 3333","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T18:38:53.421967Z","iopub.execute_input":"2025-11-08T18:38:53.422367Z","iopub.status.idle":"2025-11-08T18:38:53.431417Z","shell.execute_reply.started":"2025-11-08T18:38:53.422339Z","shell.execute_reply":"2025-11-08T18:38:53.430110Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 1. Предобработка данных","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ndf_train_base = pd.read_csv('/kaggle/input/spaceship-titanic/train.csv')\ndf_test_base = pd.read_csv('/kaggle/input/spaceship-titanic/test.csv')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-08T18:38:53.438821Z","iopub.execute_input":"2025-11-08T18:38:53.439706Z","iopub.status.idle":"2025-11-08T18:38:53.975471Z","shell.execute_reply.started":"2025-11-08T18:38:53.439672Z","shell.execute_reply":"2025-11-08T18:38:53.974273Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train_base.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T18:38:53.977170Z","iopub.execute_input":"2025-11-08T18:38:53.977547Z","iopub.status.idle":"2025-11-08T18:38:54.016026Z","shell.execute_reply.started":"2025-11-08T18:38:53.977520Z","shell.execute_reply":"2025-11-08T18:38:54.015043Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Объединю тренировочный и тестовый датасет для удобства обработки и избавлюсь от очевидно лишних фич (id и имя):","metadata":{}},{"cell_type":"code","source":"df_test_base['Transported'] = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T18:38:54.017141Z","iopub.execute_input":"2025-11-08T18:38:54.017505Z","iopub.status.idle":"2025-11-08T18:38:54.024697Z","shell.execute_reply.started":"2025-11-08T18:38:54.017475Z","shell.execute_reply":"2025-11-08T18:38:54.023544Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.concat([df_train_base, df_test_base])\ndf = df.drop(columns=['PassengerId', 'Name'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T18:38:54.026750Z","iopub.execute_input":"2025-11-08T18:38:54.027042Z","iopub.status.idle":"2025-11-08T18:38:54.052480Z","shell.execute_reply.started":"2025-11-08T18:38:54.027018Z","shell.execute_reply":"2025-11-08T18:38:54.051513Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"В описании датасета сказано: \"Cabin - The cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either P for Port or S for Starboard.\" => разделю фичу Cabin на 3 фичи Deck, Num, Side:","metadata":{}},{"cell_type":"code","source":"df[['Deck', 'Num', 'Side']] = df['Cabin'].str.split('/', expand=True)\ndf['Num'] = pd.to_numeric(df['Num'])\ndf = df.drop(columns=['Cabin'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T18:38:54.053407Z","iopub.execute_input":"2025-11-08T18:38:54.053706Z","iopub.status.idle":"2025-11-08T18:38:54.087081Z","shell.execute_reply.started":"2025-11-08T18:38:54.053677Z","shell.execute_reply":"2025-11-08T18:38:54.085964Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T18:38:54.088259Z","iopub.execute_input":"2025-11-08T18:38:54.088692Z","iopub.status.idle":"2025-11-08T18:38:54.107897Z","shell.execute_reply.started":"2025-11-08T18:38:54.088656Z","shell.execute_reply":"2025-11-08T18:38:54.107052Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"В датасете есть пропуски. Есть вариант удалить объекты с пропусками, но я воспользуюсь KNNImputer, который использует алгоритм k ближайших соседей, для заполнения NaN значений у количественных фич. Для номинальных же добавлю новое значение - 'unknown'","metadata":{}},{"cell_type":"code","source":"from sklearn.impute import KNNImputer\n\nimp = KNNImputer()\nimpute_list = ['Age', 'VIP', 'Num', 'CryoSleep', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\nrest_list = list(set(df.columns) - set(impute_list))\ndf_imputed = pd.DataFrame(imp.fit_transform(df[impute_list]), columns=impute_list)\ndf_rest = df[rest_list]\ndf = pd.concat([df_rest.reset_index(drop=True), df_imputed.reset_index(drop=True)], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T18:38:54.108863Z","iopub.execute_input":"2025-11-08T18:38:54.109138Z","iopub.status.idle":"2025-11-08T18:38:57.579064Z","shell.execute_reply.started":"2025-11-08T18:38:54.109114Z","shell.execute_reply":"2025-11-08T18:38:57.578146Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['Destination'] = df['Destination'].fillna('unknown')\ndf['Deck'] = df['Deck'].fillna('unknown')\ndf['Side'] = df['Side'].fillna('unknown')\ndf['HomePlanet'] = df['HomePlanet'].fillna('unknown')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T18:38:57.580067Z","iopub.execute_input":"2025-11-08T18:38:57.580878Z","iopub.status.idle":"2025-11-08T18:38:57.594089Z","shell.execute_reply.started":"2025-11-08T18:38:57.580845Z","shell.execute_reply":"2025-11-08T18:38:57.593164Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Составлю матрицу корреляции для количественных признаков и увижу, что признаки слабо коррелируют => никакие удалять не нужно.","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\n\nsns.heatmap(df[['Age', 'VIP', 'Num', 'CryoSleep', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].corr(), cmap='coolwarm')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T18:38:57.595003Z","iopub.execute_input":"2025-11-08T18:38:57.595293Z","iopub.status.idle":"2025-11-08T18:38:58.592935Z","shell.execute_reply.started":"2025-11-08T18:38:57.595265Z","shell.execute_reply":"2025-11-08T18:38:58.592123Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Рассмотрю номинальные фичи и замечу, что уникальных значений довольно мало => можно воспользоваться One Hot Encoding вместо Label Encoding/Frequency Encoding.","metadata":{}},{"cell_type":"code","source":"print(df['Destination'].unique())\nprint(df['Deck'].unique())\nprint(df['Side'].unique())\nprint(df['HomePlanet'].unique())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T18:38:58.595723Z","iopub.execute_input":"2025-11-08T18:38:58.596219Z","iopub.status.idle":"2025-11-08T18:38:58.609021Z","shell.execute_reply.started":"2025-11-08T18:38:58.596168Z","shell.execute_reply":"2025-11-08T18:38:58.608113Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.get_dummies(df, columns=['HomePlanet', 'Destination', 'Deck', 'Side'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T18:38:58.610101Z","iopub.execute_input":"2025-11-08T18:38:58.610611Z","iopub.status.idle":"2025-11-08T18:38:58.655528Z","shell.execute_reply.started":"2025-11-08T18:38:58.610576Z","shell.execute_reply":"2025-11-08T18:38:58.654489Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Проверю, что все NaN значения у объектов были убраны:","metadata":{}},{"cell_type":"code","source":"df.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T18:38:58.656819Z","iopub.execute_input":"2025-11-08T18:38:58.657158Z","iopub.status.idle":"2025-11-08T18:38:58.669397Z","shell.execute_reply.started":"2025-11-08T18:38:58.657127Z","shell.execute_reply":"2025-11-08T18:38:58.668467Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Разделю датасет обратно на тренировочный и тестовый:","metadata":{}},{"cell_type":"code","source":"df_train, df_test = df[:df_train_base.shape[0]], df[df_train_base.shape[0]:].drop(columns=['Transported'])\nx_train = df_train.drop(columns=['Transported'])\ny_train = df_train['Transported']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T18:38:58.670430Z","iopub.execute_input":"2025-11-08T18:38:58.670771Z","iopub.status.idle":"2025-11-08T18:38:58.681717Z","shell.execute_reply.started":"2025-11-08T18:38:58.670743Z","shell.execute_reply":"2025-11-08T18:38:58.680703Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. Выбор и обучение модели","metadata":{}},{"cell_type":"markdown","source":"Для выбора модели напишу функцию, которая разделит тренировочный датасет в соотношении 80/20 и будет вычислять метрику accuracy на основе этого разделения. Протестирую модели, пока без тюнинга гиперпараметров (прописанный verbose нужен лишь для сокращения вывода, а max_iter в LogisticRegression, чтобы убрать назойливый warning -_-)","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\ndef test_model(train, test, model_type, **kwargs):\n    x_train, x_test, y_train, y_test = train_test_split(train, test, random_state=SEED, test_size=0.2)    \n    model = model_type(**kwargs)\n    model.fit(x_train, y_train)\n    y_pred = model.predict(x_test)\n    return accuracy_score(y_pred, y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T18:38:58.682513Z","iopub.execute_input":"2025-11-08T18:38:58.682760Z","iopub.status.idle":"2025-11-08T18:38:58.700405Z","shell.execute_reply.started":"2025-11-08T18:38:58.682740Z","shell.execute_reply":"2025-11-08T18:38:58.699097Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\n\nprint(f'LogisticRegression: {test_model(x_train, y_train, LogisticRegression, verbose=0, max_iter=1000)}')\nprint(f'DecisionTreeClassifier: {test_model(x_train, y_train, DecisionTreeClassifier)}')\nprint(f'RandomForestClassifier: {test_model(x_train, y_train, RandomForestClassifier, verbose=0)}')\nprint(f'LGBMClassifier: {test_model(x_train, y_train, LGBMClassifier, verbose=-1)}')\nprint(f'XGBClassifier: {test_model(x_train, y_train, XGBClassifier)}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T18:38:58.701893Z","iopub.execute_input":"2025-11-08T18:38:58.702370Z","iopub.status.idle":"2025-11-08T18:39:12.024962Z","shell.execute_reply.started":"2025-11-08T18:38:58.702331Z","shell.execute_reply":"2025-11-08T18:39:12.023412Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Как можно увидеть LGBMClassifier получил лучший результат, осталось подобрать параметры, для этого воспользуюсь RandomizedSearchCV (optuna мне не понравилась + концептуально она делает то же самое)","metadata":{}},{"cell_type":"code","source":"# from sklearn.model_selection import RandomizedSearchCV\n# import numpy as np\n\n# model = LGBMClassifier(\n#     n_jobs=1,\n#     verbose=-1,\n#     force_row_wise=True\n# )\n\n# param_dist = {\n#     'n_estimators': np.arange(100, 1000),\n#     'max_depth': np.arange(2, 10),\n#     'num_leaves': np.arange(20, 200, 10),\n# }\n\n# random_search = RandomizedSearchCV(\n#     estimator=model,\n#     param_distributions=param_dist,\n#     n_iter=1000,\n#     cv=5,\n#     n_jobs=-1,\n#     scoring='accuracy',\n#     random_state=SEED\n# )\n\n# random_search.fit(x_train, y_train)\n\n# print(random_search.best_params_)\n# print(random_search.best_score_)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T18:39:12.025957Z","iopub.execute_input":"2025-11-08T18:39:12.026677Z","iopub.status.idle":"2025-11-08T19:05:26.550569Z","shell.execute_reply.started":"2025-11-08T18:39:12.026641Z","shell.execute_reply":"2025-11-08T19:05:26.549541Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Немного поменяю итоговые гиперпаметры вручную (а именно параметр max_depth) для достижения максимального результата в функции test_model. Обучу модель с данными гиперпараметрами и попытаюсь предсказать значения для тестового датасета у целевой фичи.","metadata":{}},{"cell_type":"code","source":"print(f'LGBMClassifier: {test_model(x_train, y_train, LGBMClassifier, random_state=SEED, verbose=-1, num_leaves=170, n_estimators=176, max_depth=4)}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T19:11:35.104497Z","iopub.execute_input":"2025-11-08T19:11:35.104829Z","iopub.status.idle":"2025-11-08T19:11:35.308800Z","shell.execute_reply.started":"2025-11-08T19:11:35.104807Z","shell.execute_reply":"2025-11-08T19:11:35.307732Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = LGBMClassifier(random_state=SEED, verbose=-1, num_leaves=170, n_estimators=176, max_depth=4)\nmodel.fit(x_train, y_train)\ny_pred = model.predict(df_test)\nsubmission = pd.DataFrame({'PassengerId': df_test_base.PassengerId, 'Transported': y_pred})\nsubmission.to_csv('/kaggle/working/submission.csv', index=False)\nsubmission.to_csv('./submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T19:15:06.040926Z","iopub.execute_input":"2025-11-08T19:15:06.041342Z","iopub.status.idle":"2025-11-08T19:15:06.275302Z","shell.execute_reply.started":"2025-11-08T19:15:06.041316Z","shell.execute_reply":"2025-11-08T19:15:06.274369Z"}},"outputs":[],"execution_count":null}]}